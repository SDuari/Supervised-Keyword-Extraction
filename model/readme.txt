The pre-trained XGBoost2 model as reported in our paper.

Training Corpus: Hulth2003 (1500 docs, Train + Test) and SemEval2010 (244 docs, Train + Test)


